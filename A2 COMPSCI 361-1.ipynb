{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from autorank import autorank, plot_stats\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "ALGORITHM_NAMES = [\"random_forest\",\"decision_stump\",\"unpruned_decision_tree\",\"pruned_decision_tree\"]\n",
    "\n",
    "labels = pd.read_csv(\"labels_A2.csv\", header = None)\n",
    "labels.columns = [\"target_variable\"]\n",
    "data = pd.read_csv(\"data_A2.csv\", header = None)\n",
    "\n",
    "#Task One, dealing with missing values\n",
    "imputer = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "data=pd.DataFrame(imputer.fit_transform(data))\n",
    "data.head(5) #only showing 5 for space\n",
    "\n",
    "#Creating dataset with Target noise\n",
    "flip = np.random.binomial(1, 0.05, np.array(labels.iloc[:,0]).shape).astype(bool)\n",
    "task_6_targets = pd.DataFrame(np.where(flip, 1 - np.array(labels.iloc[:,0]),np.array(labels.iloc[:,0])))\n",
    "\n",
    "repeated_k_fold = RepeatedKFold(n_splits=10, n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>78</th>\n",
       "      <th>77</th>\n",
       "      <th>92</th>\n",
       "      <th>64</th>\n",
       "      <th>95</th>\n",
       "      <th>4</th>\n",
       "      <th>96</th>\n",
       "      <th>43</th>\n",
       "      <th>67</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.722900</td>\n",
       "      <td>-0.215309</td>\n",
       "      <td>-0.867395</td>\n",
       "      <td>1.424084</td>\n",
       "      <td>4.107535</td>\n",
       "      <td>-1.366659</td>\n",
       "      <td>3.817897</td>\n",
       "      <td>-1.919015</td>\n",
       "      <td>-0.916539</td>\n",
       "      <td>0.294604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.492973</td>\n",
       "      <td>-2.245505</td>\n",
       "      <td>-0.382098</td>\n",
       "      <td>0.471146</td>\n",
       "      <td>-1.267888</td>\n",
       "      <td>1.656770</td>\n",
       "      <td>-1.843256</td>\n",
       "      <td>1.394421</td>\n",
       "      <td>0.874010</td>\n",
       "      <td>-1.731359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.247858</td>\n",
       "      <td>-3.416490</td>\n",
       "      <td>-4.660688</td>\n",
       "      <td>-3.615905</td>\n",
       "      <td>-4.317565</td>\n",
       "      <td>-1.733342</td>\n",
       "      <td>-2.506476</td>\n",
       "      <td>-0.290845</td>\n",
       "      <td>-1.840549</td>\n",
       "      <td>-0.520724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.338379</td>\n",
       "      <td>1.198258</td>\n",
       "      <td>7.150844</td>\n",
       "      <td>2.767716</td>\n",
       "      <td>-0.081950</td>\n",
       "      <td>-0.416290</td>\n",
       "      <td>0.186089</td>\n",
       "      <td>1.046033</td>\n",
       "      <td>-0.279751</td>\n",
       "      <td>-2.133925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.575898</td>\n",
       "      <td>-1.122903</td>\n",
       "      <td>3.576609</td>\n",
       "      <td>2.773314</td>\n",
       "      <td>-2.613114</td>\n",
       "      <td>-0.075077</td>\n",
       "      <td>-3.117484</td>\n",
       "      <td>1.371734</td>\n",
       "      <td>-1.755619</td>\n",
       "      <td>0.251593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         78        77        92        64        95        4         96  \\\n",
       "0 -0.722900 -0.215309 -0.867395  1.424084  4.107535 -1.366659  3.817897   \n",
       "1  2.492973 -2.245505 -0.382098  0.471146 -1.267888  1.656770 -1.843256   \n",
       "2 -0.247858 -3.416490 -4.660688 -3.615905 -4.317565 -1.733342 -2.506476   \n",
       "3 -1.338379  1.198258  7.150844  2.767716 -0.081950 -0.416290  0.186089   \n",
       "4  3.575898 -1.122903  3.576609  2.773314 -2.613114 -0.075077 -3.117484   \n",
       "\n",
       "         43        67        38  \n",
       "0 -1.919015 -0.916539  0.294604  \n",
       "1  1.394421  0.874010 -1.731359  \n",
       "2 -0.290845 -1.840549 -0.520724  \n",
       "3  1.046033 -0.279751 -2.133925  \n",
       "4  1.371734 -1.755619  0.251593  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean dataset\n",
    "dataframes = [data,labels]\n",
    "full = pd.concat(dataframes, axis=1)\n",
    "correlations = full.corr(method=\"pearson\")\n",
    "target_variable_correlation = np.array(correlations.iloc[:,-1])[:-1]\n",
    "copy = [x for x in target_variable_correlation]\n",
    "copy.sort()\n",
    "copy = copy[::-1]\n",
    "indexes = [list(target_variable_correlation).index(value) for value in copy]\n",
    "\n",
    "\n",
    "top_ten_indexes = []\n",
    "while len(top_ten_indexes) < 10:\n",
    "    correlation_value = copy[0]\n",
    "    if len(top_ten_indexes)!= 0:\n",
    "        similarity_count  = 0 \n",
    "        index = indexes[0]\n",
    "        column1 = data.iloc[:,index]\n",
    "        for a in range(len(top_ten_indexes)):\n",
    "            count = 0\n",
    "            column2 = data.iloc[:,top_ten_indexes[a]]\n",
    "            for number in range(1000):\n",
    "                if column1[number] == column2[number]:\n",
    "                    count +=1\n",
    "            if similarity_count < count:\n",
    "                similarity_count = count\n",
    "        if similarity_count < 500:\n",
    "            top_ten_indexes.append(index)     \n",
    "    else:\n",
    "        top_ten_indexes.append(indexes[0])\n",
    "    copy = copy[1:]\n",
    "    indexes = indexes[1:]\n",
    "    \n",
    "new_columns = [data.iloc[:,index] for index in top_ten_indexes]\n",
    "cleaned_features = pd.concat(new_columns, axis=1)\n",
    "\n",
    "cleaned_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RankResult(rankdf=\n",
      "                        meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "random_forest              1.250  0.7216  0.041772  0.713789  0.729411   \n",
      "unpruned_decision_tree     2.420  0.6485  0.043794  0.640689  0.656311   \n",
      "pruned_decision_tree       2.965  0.6317  0.041707  0.623889  0.639511   \n",
      "decision_stump             3.365  0.6080  0.043924  0.600189  0.615811   \n",
      "\n",
      "                       effect_size   magnitude  \n",
      "random_forest                    0  negligible  \n",
      "unpruned_decision_tree     1.70814       large  \n",
      "pruned_decision_tree       2.15383       large  \n",
      "decision_stump             2.65041       large  \n",
      "pvalue=1.5783662832414107e-53\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.5841171145439148, 0.4552447497844696, 0.023776041343808174, 0.15958285331726074]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.9222673283626363\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n"
     ]
    }
   ],
   "source": [
    "#TASK 3\n",
    "ALGORITHM_NAMES = [\"random_forest\",\"decision_stump\",\"unpruned_decision_tree\",\"pruned_decision_tree\"]\n",
    "task_3_dataframe = pd.DataFrame (columns = ALGORITHM_NAMES)\n",
    "random_forest = RandomForestClassifier()\n",
    "decision_stump = DecisionTreeClassifier(max_depth=1)\n",
    "decision_tree_unpruned = DecisionTreeClassifier()\n",
    "random_forest_task_3 = cross_val_score(random_forest, cleaned_features, labels, cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "decision_stump_task_3 = cross_val_score(decision_stump, cleaned_features, labels, cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "unpruned_decision_tree_task_3 = cross_val_score(decision_tree_unpruned, cleaned_features, labels, cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "task_3_dataframe[ALGORITHM_NAMES[0]] = random_forest_task_3\n",
    "task_3_dataframe[ALGORITHM_NAMES[1]]= decision_stump_task_3\n",
    "task_3_dataframe[ALGORITHM_NAMES[2]]= unpruned_decision_tree_task_3\n",
    "\n",
    "pruned_decision_tree_task_3 = []\n",
    "for train_index, test_index in repeated_k_fold.split(cleaned_features):\n",
    "    train_indexes = list(train_index)\n",
    "    training_x = cleaned_features.loc[train_indexes]\n",
    "    training_y = labels.loc[train_indexes]\n",
    "    x_train,x_validate,y_train, y_validate = train_test_split(training_x, training_y,test_size=0.30)\n",
    "    path = DecisionTreeClassifier().cost_complexity_pruning_path(x_train, y_train)\n",
    "    highest_accuracy,ccp_alpha_value = 0.0, 0\n",
    "    for value in path.ccp_alphas:\n",
    "        accuracy = DecisionTreeClassifier(ccp_alpha=value).fit(x_train, y_train.values.ravel()).score(x_validate, y_validate)\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy, ccp_alpha_value = accuracy, value\n",
    "    test_indexes = list(test_index)\n",
    "    test_x = cleaned_features.loc[test_indexes]\n",
    "    test_y = labels.loc[test_indexes]\n",
    "    decision_tree_pruned = DecisionTreeClassifier(ccp_alpha = ccp_alpha_value)\n",
    "    accuracy = decision_tree_pruned.fit(training_x,training_y.values.ravel()).score(test_x,test_y)\n",
    "    pruned_decision_tree_task_3.append(accuracy)\n",
    "task_3_dataframe[ALGORITHM_NAMES[3]]= pruned_decision_tree_task_3\n",
    "task_3_result = autorank(task_3_dataframe, alpha=0.05, verbose=False)\n",
    "print(task_3_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RankResult(rankdf=\n",
      "                        meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "random_forest              1.250  0.7201  0.042604  0.711656  0.728544   \n",
      "pruned_decision_tree       2.640  0.6425  0.049121  0.634056  0.650944   \n",
      "unpruned_decision_tree     2.755  0.6401  0.045848  0.631656  0.648544   \n",
      "decision_stump             3.355  0.6138  0.047328  0.605356  0.622244   \n",
      "\n",
      "                       effect_size   magnitude  \n",
      "random_forest                    0  negligible  \n",
      "pruned_decision_tree       1.68775       large  \n",
      "unpruned_decision_tree     1.80767       large  \n",
      "decision_stump             2.36074       large  \n",
      "pvalue=1.678738485751227e-45\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.050294648855924606, 0.5874094367027283, 0.8740835785865784, 0.636618435382843]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.546912328718421\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n"
     ]
    }
   ],
   "source": [
    "#Task 4\n",
    "\n",
    "#Creating dataset with additive noise, taken from piazza\n",
    "a_noise = np.random.normal(0, 0.2, np.shape(cleaned_features))\n",
    "a_noise_data = cleaned_features + np.multiply(a_noise, np.average(cleaned_features, axis=0))\n",
    "task_4_features = pd.DataFrame(a_noise_data)\n",
    "\n",
    "task_4_dataframe = pd.DataFrame (columns = ALGORITHM_NAMES)\n",
    "random_forest = RandomForestClassifier()\n",
    "decision_stump = DecisionTreeClassifier(max_depth=1)\n",
    "decision_tree_unpruned = DecisionTreeClassifier()\n",
    "random_forest_task_4 = cross_val_score(random_forest, task_4_features, labels, cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "decision_stump_task_4 = cross_val_score(decision_stump, task_4_features, labels, cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "unpruned_decision_tree_task_4 = cross_val_score(decision_tree_unpruned, task_4_features, labels, cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "task_4_dataframe[ALGORITHM_NAMES[0]] = random_forest_task_4\n",
    "task_4_dataframe[ALGORITHM_NAMES[1]]= decision_stump_task_4\n",
    "task_4_dataframe[ALGORITHM_NAMES[2]]= unpruned_decision_tree_task_4\n",
    "\n",
    "pruned_decision_tree_task_4 = []\n",
    "for train_index, test_index in repeated_k_fold.split(task_4_features):\n",
    "    train_indexes = list(train_index)\n",
    "    training_x = task_4_features.loc[train_indexes]\n",
    "    training_y = labels.loc[train_indexes]\n",
    "    x_train,x_validate,y_train, y_validate = train_test_split(training_x, training_y,test_size=0.30)\n",
    "    path = DecisionTreeClassifier().cost_complexity_pruning_path(x_train, y_train)\n",
    "    highest_accuracy,ccp_alpha_value = 0.0, 0\n",
    "    for value in path.ccp_alphas:\n",
    "        accuracy = DecisionTreeClassifier(ccp_alpha=value).fit(x_train, y_train.values.ravel()).score(x_validate, y_validate)\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy, ccp_alpha_value = accuracy, value\n",
    "    test_indexes = list(test_index)\n",
    "    test_x = task_4_features.loc[test_indexes]\n",
    "    test_y = labels.loc[test_indexes]\n",
    "    decision_tree_pruned = DecisionTreeClassifier(ccp_alpha = ccp_alpha_value)\n",
    "    accuracy = decision_tree_pruned.fit(training_x,training_y.values.ravel()).score(test_x,test_y)\n",
    "    pruned_decision_tree_task_4.append(accuracy)\n",
    "task_4_dataframe[ALGORITHM_NAMES[3]]= pruned_decision_tree_task_4\n",
    "task_4_result = autorank(task_4_dataframe, alpha=0.05, verbose=False)\n",
    "print(task_4_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RankResult(rankdf=\n",
      "                        meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "random_forest              1.330  0.7149  0.047001  0.706268  0.723532   \n",
      "pruned_decision_tree       2.525  0.6487  0.052081  0.640068  0.657332   \n",
      "unpruned_decision_tree     2.775  0.6398  0.043251  0.631168  0.648432   \n",
      "decision_stump             3.370  0.6100  0.046493  0.601368  0.618632   \n",
      "\n",
      "                       effect_size   magnitude  \n",
      "random_forest                    0  negligible  \n",
      "pruned_decision_tree       1.33452       large  \n",
      "unpruned_decision_tree     1.66279       large  \n",
      "decision_stump             2.24396       large  \n",
      "pvalue=9.201963221579113e-41\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.34087854623794556, 0.05607712268829346, 0.3257023096084595, 0.2571146786212921]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.3200294581372539\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n"
     ]
    }
   ],
   "source": [
    "#Task 5\n",
    "#Creating dataset with muliplicative noise, taken from piazza\n",
    "m_noise = np.random.normal(1, 0.2, np.shape(cleaned_features))\n",
    "m_noise_data = np.multiply(cleaned_features, m_noise)\n",
    "task_5_features = pd.DataFrame(m_noise_data)\n",
    "\n",
    "task_5_dataframe = pd.DataFrame (columns = ALGORITHM_NAMES)\n",
    "random_forest = RandomForestClassifier()\n",
    "decision_stump = DecisionTreeClassifier(max_depth=1)\n",
    "decision_tree_unpruned = DecisionTreeClassifier()\n",
    "random_forest_task_5 = cross_val_score(random_forest, task_5_features, labels.iloc[:,0], cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "decision_stump_task_5 = cross_val_score(decision_stump, task_5_features, labels.iloc[:,0], cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "unpruned_decision_tree_task_5 = cross_val_score(decision_tree_unpruned, task_5_features, labels.iloc[:,0], cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "task_5_dataframe[ALGORITHM_NAMES[0]] = random_forest_task_5\n",
    "task_5_dataframe[ALGORITHM_NAMES[1]]= decision_stump_task_5\n",
    "task_5_dataframe[ALGORITHM_NAMES[2]]= unpruned_decision_tree_task_5\n",
    "\n",
    "pruned_decision_tree_task_5 = []\n",
    "for train_index, test_index in repeated_k_fold.split(cleaned_features):\n",
    "    train_indexes = list(train_index)\n",
    "    training_x = task_5_features.loc[train_indexes]\n",
    "    training_y = labels.loc[train_indexes]\n",
    "    x_train,x_validate,y_train, y_validate = train_test_split(training_x, training_y,test_size=0.30)\n",
    "    path = DecisionTreeClassifier().cost_complexity_pruning_path(x_train, y_train)\n",
    "    highest_accuracy,ccp_alpha_value = 0.0, 0\n",
    "    for value in path.ccp_alphas:\n",
    "        accuracy = DecisionTreeClassifier(ccp_alpha=value).fit(x_train, y_train.values.ravel()).score(x_validate, y_validate)\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy, ccp_alpha_value = accuracy, value\n",
    "    test_indexes = list(test_index)\n",
    "    test_x = task_5_features.loc[test_indexes]\n",
    "    test_y = labels.loc[test_indexes]\n",
    "    decision_tree_pruned = DecisionTreeClassifier(ccp_alpha = ccp_alpha_value)\n",
    "    accuracy = decision_tree_pruned.fit(training_x,training_y.values.ravel()).score(test_x,test_y)\n",
    "    pruned_decision_tree_task_5.append(accuracy)\n",
    "task_5_dataframe[ALGORITHM_NAMES[3]]= pruned_decision_tree_task_5\n",
    "task_5_result = autorank(task_5_dataframe, alpha=0.05, verbose=False)\n",
    "print(task_5_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RankResult(rankdf=\n",
      "                        meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "random_forest              1.375  0.6795  0.046696  0.671049  0.687951   \n",
      "pruned_decision_tree       2.630  0.6132  0.049561  0.604749  0.621651   \n",
      "unpruned_decision_tree     2.870  0.6024  0.046648  0.593949  0.610851   \n",
      "decision_stump             3.125  0.5915  0.042077  0.583049  0.599951   \n",
      "\n",
      "                       effect_size   magnitude  \n",
      "random_forest                    0  negligible  \n",
      "pruned_decision_tree       1.37694       large  \n",
      "unpruned_decision_tree     1.65195       large  \n",
      "decision_stump              1.9799       large  \n",
      "pvalue=1.4672756472598458e-34\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.8119857907295227, 0.6176819205284119, 0.29801955819129944, 0.48048049211502075]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.44435675954245457\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n"
     ]
    }
   ],
   "source": [
    "#task 6\n",
    "task_6_dataframe = pd.DataFrame (columns = ALGORITHM_NAMES)\n",
    "random_forest = RandomForestClassifier()\n",
    "decision_stump = DecisionTreeClassifier(max_depth=1)\n",
    "decision_tree_unpruned = DecisionTreeClassifier()\n",
    "random_forest_task_6 = cross_val_score(random_forest, cleaned_features, task_6_targets, cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "decision_stump_task_6 = cross_val_score(decision_stump, cleaned_features, task_6_targets, cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "unpruned_decision_tree_task_6 = cross_val_score(decision_tree_unpruned, cleaned_features, task_6_targets, cv=repeated_k_fold, scoring='accuracy',n_jobs = -1)\n",
    "task_6_dataframe[ALGORITHM_NAMES[0]] = random_forest_task_6\n",
    "task_6_dataframe[ALGORITHM_NAMES[1]]= decision_stump_task_6\n",
    "task_6_dataframe[ALGORITHM_NAMES[2]]= unpruned_decision_tree_task_6\n",
    "\n",
    "pruned_decision_tree_task_6 = []\n",
    "for train_index, test_index in repeated_k_fold.split(cleaned_features):\n",
    "    train_indexes = list(train_index)\n",
    "    training_x = cleaned_features.loc[train_indexes]\n",
    "    training_y = task_6_targets.loc[train_indexes]\n",
    "    x_train,x_validate,y_train, y_validate = train_test_split(training_x, training_y,test_size=0.30)\n",
    "    path = DecisionTreeClassifier().cost_complexity_pruning_path(x_train, y_train)\n",
    "    highest_accuracy,ccp_alpha_value = 0.0, 0\n",
    "    for value in path.ccp_alphas:\n",
    "        accuracy = DecisionTreeClassifier(ccp_alpha=value).fit(x_train, y_train.values.ravel()).score(x_validate, y_validate)\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy, ccp_alpha_value = accuracy, value\n",
    "    test_indexes = list(test_index)\n",
    "    test_x = cleaned_features.loc[test_indexes]\n",
    "    test_y = task_6_targets.loc[test_indexes]\n",
    "    decision_tree_pruned = DecisionTreeClassifier(ccp_alpha = ccp_alpha_value)\n",
    "    accuracy = decision_tree_pruned.fit(training_x,training_y.values.ravel()).score(test_x,test_y)\n",
    "    pruned_decision_tree_task_6.append(accuracy)\n",
    "task_6_dataframe[ALGORITHM_NAMES[3]]= pruned_decision_tree_task_6\n",
    "task_6_result = autorank(task_6_dataframe, alpha=0.05, verbose=False)\n",
    "print(task_6_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RankResult(rankdf=\n",
      "                        meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "random_forest              1.155  0.7173  0.045767  0.709104  0.725496   \n",
      "pruned_decision_tree       2.590  0.6465  0.041081  0.638304  0.654696   \n",
      "unpruned_decision_tree     2.850  0.6382  0.041643  0.630004  0.646396   \n",
      "decision_stump             3.405  0.6116  0.050567  0.603404  0.619796   \n",
      "\n",
      "                       effect_size   magnitude  \n",
      "random_forest                    0  negligible  \n",
      "pruned_decision_tree       1.62806       large  \n",
      "unpruned_decision_tree     1.80785       large  \n",
      "decision_stump             2.19172       large  \n",
      "pvalue=6.629142541543662e-62\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.7044161558151245, 0.20814861357212067, 0.33433419466018677, 0.1336606740951538]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.13123447720280806\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n"
     ]
    }
   ],
   "source": [
    "#task 7a mulitplicative noise to training only\n",
    "\n",
    "\n",
    "task_7_dataframe = pd.DataFrame (columns = ALGORITHM_NAMES)\n",
    "random_forest = RandomForestClassifier()\n",
    "decision_stump = DecisionTreeClassifier(max_depth=1)\n",
    "decision_tree_unpruned = DecisionTreeClassifier()\n",
    "algorithms = [random_forest, decision_stump, decision_tree_unpruned,decision_tree_pruned]\n",
    "\n",
    "results = {value:[] for value in ALGORITHM_NAMES}\n",
    "for train_index, test_index in repeated_k_fold.split(cleaned_features):\n",
    "    train_indexes = list(train_index)\n",
    "    training_x = cleaned_features.loc[train_indexes]\n",
    "    training_y = labels.loc[train_indexes]\n",
    "    normal_train = cleaned_features.loc[train_index]\n",
    "    m_noise = np.random.normal(1, 0.2, np.shape(training_x))\n",
    "    m_noise_training = np.multiply(training_x, m_noise)\n",
    "    noise_training = pd.DataFrame(m_noise_training)\n",
    "    \n",
    "\n",
    "    x_train,x_validate,y_train, y_validate = train_test_split(noise_training, training_y,test_size=0.30)\n",
    "    path = DecisionTreeClassifier().cost_complexity_pruning_path(x_train, y_train)\n",
    "    highest_accuracy,ccp_alpha_value = 0.0, 0\n",
    "    for value in path.ccp_alphas:\n",
    "        accuracy = DecisionTreeClassifier(ccp_alpha=value).fit(x_train, y_train.values.ravel()).score(x_validate, y_validate)\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy, ccp_alpha_value = accuracy, value\n",
    "    decision_tree_pruned = DecisionTreeClassifier(ccp_alpha = ccp_alpha_value)\n",
    "    test_indexes = list(test_index)\n",
    "    test_x = cleaned_features.loc[test_indexes]\n",
    "    test_y = labels.loc[test_indexes]\n",
    "\n",
    "    for num in range(len(ALGORITHM_NAMES)):\n",
    "        accuracy = algorithms[num].fit(training_x,training_y.values.ravel()).score(test_x,test_y.values.ravel())\n",
    "        results[ALGORITHM_NAMES[num]].append(accuracy)\n",
    "for p in range(len(ALGORITHM_NAMES)):\n",
    "    task_7_dataframe[ALGORITHM_NAMES[p]] = results[ALGORITHM_NAMES[p]]\n",
    "result = autorank(task_7_dataframe, alpha=0.05, verbose=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RankResult(rankdf=\n",
      "                        meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "random_forest              1.125  0.7203  0.040984  0.711988  0.728612   \n",
      "unpruned_decision_tree     2.720  0.6397  0.048272  0.631388  0.648012   \n",
      "pruned_decision_tree       2.730  0.6397  0.045226  0.631388  0.648012   \n",
      "decision_stump             3.425  0.6139  0.047416  0.605588  0.622212   \n",
      "\n",
      "                       effect_size   magnitude  \n",
      "random_forest                    0  negligible  \n",
      "unpruned_decision_tree     1.80004       large  \n",
      "pruned_decision_tree        1.8676       large  \n",
      "decision_stump             2.40089       large  \n",
      "pvalue=9.826818346502524e-64\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.3564307391643524, 0.22958727180957794, 0.07281657308340073, 0.16306118667125702]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.37946682411442395\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n"
     ]
    }
   ],
   "source": [
    "#task 7b mulitplicative noise to test only\n",
    "\n",
    "\n",
    "task_7b_dataframe = pd.DataFrame (columns = ALGORITHM_NAMES)\n",
    "random_forest = RandomForestClassifier()\n",
    "decision_stump = DecisionTreeClassifier(max_depth=1)\n",
    "decision_tree_unpruned = DecisionTreeClassifier()\n",
    "algorithms = [random_forest, decision_stump, decision_tree_unpruned,decision_tree_pruned]\n",
    "\n",
    "results = {value:[] for value in ALGORITHM_NAMES}\n",
    "for train_index, test_index in repeated_k_fold.split(cleaned_features):\n",
    "    train_indexes = list(train_index)\n",
    "    training_x = cleaned_features.loc[train_indexes]\n",
    "    training_y = labels.loc[train_indexes]\n",
    "    x_train,x_validate,y_train, y_validate = train_test_split(noise_training, training_y,test_size=0.30)\n",
    "    path = DecisionTreeClassifier().cost_complexity_pruning_path(x_train, y_train)\n",
    "    highest_accuracy,ccp_alpha_value = 0.0, 0\n",
    "    for value in path.ccp_alphas:\n",
    "        accuracy = DecisionTreeClassifier(ccp_alpha=value).fit(x_train, y_train.values.ravel()).score(x_validate, y_validate)\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy, ccp_alpha_value = accuracy, value\n",
    "    test_indexes = list(test_index)\n",
    "    test_x = cleaned_features.loc[test_indexes]\n",
    "    test_y = labels.loc[test_indexes]\n",
    "    m_noise = np.random.normal(1, 0.2, np.shape(test_x))\n",
    "    m_noise_test = np.multiply(test_x,m_noise)\n",
    "    noise_test = pd.DataFrame(m_noise_test)\n",
    "    decision_tree_pruned = DecisionTreeClassifier(ccp_alpha = ccp_alpha_value)\n",
    "    for num in range(len(ALGORITHM_NAMES)):\n",
    "        accuracy = algorithms[num].fit(training_x,training_y.values.ravel()).score(test_x,test_y)\n",
    "        results[ALGORITHM_NAMES[num]].append(accuracy)\n",
    "for p in range(len(ALGORITHM_NAMES)):\n",
    "    task_7b_dataframe[ALGORITHM_NAMES[p]] = results[ALGORITHM_NAMES[p]]\n",
    "result = autorank(task_7b_dataframe, alpha=0.05, verbose=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task3     1.465  0.7216  0.041772  0.712093  0.731107           0  negligible\n",
      "Task4     1.535  0.7201  0.042604  0.710403  0.729797   0.0355533  negligible\n",
      "pvalue=0.7868765259832449\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.5841171145439148, 0.050294648855924606]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.844709707878143\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "decision_stump\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task3     1.465  0.6080  0.043924  0.598003  0.617997           0  negligible\n",
      "Task4     1.535  0.6138  0.047328  0.603028  0.624572   -0.127032  negligible\n",
      "pvalue=0.42899567568126606\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.4552447497844696, 0.5874094367027283]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.45895603528103024\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "unpruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "       meanrank  median       mad ci_lower ci_upper effect_size   magnitude\n",
      "Task3      1.44   0.645  0.037065     0.63     0.67           0  negligible\n",
      "Task4      1.56   0.640  0.044478     0.62     0.66    0.122131  negligible\n",
      "pvalue=0.10040274188859061\n",
      "cd=None\n",
      "omnibus=wilcoxon\n",
      "posthoc=None\n",
      "all_normal=False\n",
      "pvals_shapiro=[0.023776041343808174, 0.8740835785865784]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.8272680358236022\n",
      "homogeneity_test=levene\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=akinshin_gamma)\n",
      "\n",
      "pruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task4     1.425  0.6425  0.049121   0.63132   0.65368           0  negligible\n",
      "Task3     1.575  0.6317  0.041707  0.622207  0.641193    0.237023       small\n",
      "pvalue=0.1260698924324192\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.15958285331726074, 0.636618435382843]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.10518873570088852\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis for task 4\n",
    "\n",
    "for algorithm in ALGORITHM_NAMES:\n",
    "    new = pd.DataFrame()\n",
    "    new[\"Task3\"] = list(task_3_dataframe[algorithm])\n",
    "    new[\"Task4\"] = list(task_4_dataframe[algorithm])\n",
    "    analysis_task_4 = autorank(new, alpha=0.05, verbose=False)\n",
    "    print(algorithm)\n",
    "    print(analysis_task_4)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task3      1.44  0.7216  0.041772  0.712093  0.731107           0  negligible\n",
      "Task5      1.56  0.7149  0.047001  0.704203  0.725597    0.150686  negligible\n",
      "pvalue=0.3028126354910162\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.5841171145439148, 0.34087854623794556]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.24231853956936572\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "decision_stump\n",
      "RankResult(rankdf=\n",
      "       meanrank   mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task5      1.46  0.610  0.046493  0.599418  0.620582           0  negligible\n",
      "Task3      1.54  0.608  0.043924  0.598003  0.617997   0.0442217  negligible\n",
      "pvalue=0.7566198484676405\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.4552447497844696, 0.05607712268829346]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.572694031964514\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "unpruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "       meanrank  median       mad ci_lower ci_upper effect_size   magnitude\n",
      "Task3     1.455   0.645  0.037065     0.63     0.67           0  negligible\n",
      "Task5     1.545   0.640  0.044478     0.62     0.66    0.122131  negligible\n",
      "pvalue=0.0406747808323915\n",
      "cd=None\n",
      "omnibus=wilcoxon\n",
      "posthoc=None\n",
      "all_normal=False\n",
      "pvals_shapiro=[0.023776041343808174, 0.3257023096084595]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.5992539210389576\n",
      "homogeneity_test=levene\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=akinshin_gamma)\n",
      "\n",
      "pruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task5      1.44  0.6487  0.052081  0.636846  0.660554           0  negligible\n",
      "Task3      1.56  0.6317  0.041707  0.622207  0.641193    0.360321       small\n",
      "pvalue=0.01241116212063172\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.15958285331726074, 0.2571146786212921]\n",
      "homoscedastic=False\n",
      "pval_homogeneity=0.028122690098924312\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis for task 5\n",
    "\n",
    "for algorithm in ALGORITHM_NAMES:\n",
    "    new = pd.DataFrame()\n",
    "    new[\"Task3\"] = list(task_3_dataframe[algorithm])\n",
    "    new[\"Task5\"] = list(task_5_dataframe[algorithm])\n",
    "    analysis_task_5 = autorank(new, alpha=0.05, verbose=False)\n",
    "    print(algorithm)\n",
    "    print(analysis_task_5)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task3     1.275  0.7216  0.041772  0.712093  0.731107           0  negligible\n",
      "Task6     1.725  0.6795  0.046696  0.668872  0.690128    0.950282       large\n",
      "pvalue=5.442079396224627e-09\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.5841171145439148, 0.8119857907295227]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.26919137379090113\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "decision_stump\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task3     1.355  0.6080  0.043924  0.598003  0.617997           0  negligible\n",
      "Task6     1.645  0.5915  0.042077  0.581923  0.601077     0.38363       small\n",
      "pvalue=0.007452525828782583\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.4552447497844696, 0.6176819205284119]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.6698949986553677\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "unpruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "       meanrank  median       mad ci_lower ci_upper effect_size   magnitude\n",
      "Task3     1.255   0.645  0.037065     0.63     0.67           0  negligible\n",
      "Task6     1.745   0.600  0.044478     0.59     0.63     1.09918       large\n",
      "pvalue=1.2035644621721764e-09\n",
      "cd=None\n",
      "omnibus=wilcoxon\n",
      "posthoc=None\n",
      "all_normal=False\n",
      "pvals_shapiro=[0.023776041343808174, 0.29801955819129944]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.6854766876687266\n",
      "homogeneity_test=levene\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=akinshin_gamma)\n",
      "\n",
      "pruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task3     1.375  0.6317  0.041707  0.622207  0.641193           0  negligible\n",
      "Task6     1.625  0.6132  0.049561   0.60192   0.62448    0.403904       small\n",
      "pvalue=0.005337084037493144\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.15958285331726074, 0.48048049211502075]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.08761065141140195\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis for task 6\n",
    "\n",
    "for algorithm in ALGORITHM_NAMES:\n",
    "    new = pd.DataFrame()\n",
    "    new[\"Task3\"] = list(task_3_dataframe[algorithm])\n",
    "    new[\"Task6\"] = list(task_6_dataframe[algorithm])\n",
    "    analysis_task_6 = autorank(new, alpha=0.05, verbose=False)\n",
    "    print(algorithm)\n",
    "    print(analysis_task_6)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task3      1.44  0.7216  0.041772  0.712093  0.731107           0  negligible\n",
      "Task7      1.56  0.7173  0.045767  0.706883  0.727717   0.0981394  negligible\n",
      "pvalue=0.5161298654129525\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.5841171145439148, 0.7044161558151245]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.36493646529537194\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "decision_stump\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task7     1.475  0.6116  0.050567  0.600091  0.623109           0  negligible\n",
      "Task3     1.525  0.6080  0.043924  0.598003  0.617997   0.0760104  negligible\n",
      "pvalue=0.5559567167479427\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.4552447497844696, 0.20814861357212067]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.16285317441751757\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "unpruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "       meanrank  median       mad ci_lower ci_upper effect_size   magnitude\n",
      "Task3     1.385   0.645  0.037065     0.63     0.67           0  negligible\n",
      "Task7     1.615   0.640  0.044478     0.63     0.66    0.122131  negligible\n",
      "pvalue=0.017250919827318488\n",
      "cd=None\n",
      "omnibus=wilcoxon\n",
      "posthoc=None\n",
      "all_normal=False\n",
      "pvals_shapiro=[0.023776041343808174, 0.33433419466018677]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.328716268404209\n",
      "homogeneity_test=levene\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=akinshin_gamma)\n",
      "\n",
      "pruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "       meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task7     1.425  0.6465  0.041081   0.63715   0.65585           0  negligible\n",
      "Task3     1.575  0.6317  0.041707  0.622207  0.641193    0.357529       small\n",
      "pvalue=0.01905477474922525\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.15958285331726074, 0.1336606740951538]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.8805692541451713\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis for task 7a\n",
    "\n",
    "for algorithm in ALGORITHM_NAMES:\n",
    "    new = pd.DataFrame()\n",
    "    new[\"Task3\"] = list(task_3_dataframe[algorithm])\n",
    "    new[\"Task7\"] = list(task_7_dataframe[algorithm])\n",
    "    analysis_task_7 = autorank(new, alpha=0.05, verbose=False)\n",
    "    print(algorithm)\n",
    "    print(analysis_task_7)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "RankResult(rankdf=\n",
      "        meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task3      1.495  0.7216  0.041772  0.712093  0.731107           0  negligible\n",
      "Task7b     1.505  0.7203  0.040984  0.710972  0.729628   0.0314162  negligible\n",
      "pvalue=0.8151637307167183\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.5841171145439148, 0.3564307391643524]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.8501547724701844\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "decision_stump\n",
      "RankResult(rankdf=\n",
      "        meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task7b     1.485  0.6139  0.047416  0.603108  0.624692           0  negligible\n",
      "Task3      1.515  0.6080  0.043924  0.598003  0.617997    0.129094  negligible\n",
      "pvalue=0.35171010850281226\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.4552447497844696, 0.22958727180957794]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.44789822473625673\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n",
      "unpruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "        meanrank  median       mad ci_lower ci_upper effect_size   magnitude\n",
      "Task3      1.445   0.645  0.037065     0.63     0.67           0  negligible\n",
      "Task7b     1.555   0.640  0.044478     0.62     0.66    0.122131  negligible\n",
      "pvalue=0.09642785042468605\n",
      "cd=None\n",
      "omnibus=wilcoxon\n",
      "posthoc=None\n",
      "all_normal=False\n",
      "pvals_shapiro=[0.023776041343808174, 0.07281657308340073]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.7202412890650175\n",
      "homogeneity_test=levene\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=akinshin_gamma)\n",
      "\n",
      "pruned_decision_tree\n",
      "RankResult(rankdf=\n",
      "        meanrank    mean       std  ci_lower  ci_upper effect_size   magnitude\n",
      "Task7b     1.415  0.6397  0.045226  0.629407  0.649993           0  negligible\n",
      "Task3      1.585  0.6317  0.041707  0.622207  0.641193    0.183899  negligible\n",
      "pvalue=0.20311947904352226\n",
      "cd=None\n",
      "omnibus=ttest\n",
      "posthoc=None\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.15958285331726074, 0.16306118667125702]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.4217728060463646\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.025\n",
      "num_samples=100\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis for task 7b\n",
    "\n",
    "for algorithm in ALGORITHM_NAMES:\n",
    "    new = pd.DataFrame()\n",
    "    new[\"Task3\"] = list(task_3_dataframe[algorithm])\n",
    "    new[\"Task7b\"] = list(task_7b_dataframe[algorithm])\n",
    "    analysis_task_7b = autorank(new, alpha=0.05, verbose=False)\n",
    "    print(algorithm)\n",
    "    print(analysis_task_7b)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
